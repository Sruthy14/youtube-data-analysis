{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the execution of cells based on the project report. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sruth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sruth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import statements\n",
    "#------------------------------------------------\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from IPython.display import JSON\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import isodate\n",
    "\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", color_codes=True)\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from wordcloud import WordCloud\n",
    "from google.cloud import bigquery # top upload dataframes to bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyCGYJLXOPmDHRw810nos-vfqIoFxCU2u3U'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are channel ids of most subscribed 10 youtube channels in the world\n",
    "channel_ids = ['UC-lHJZR3Gqxm24_Vd_AJ5Yw',\n",
    "               'UCq-Fj5jknLsUf-MWSy4_brA',\n",
    "               'UCbCmjCuTUZos6Inko4u57UQ',\n",
    "               'UCpEhnqL0y41EpW2TvWAHD7Q',\n",
    "               'UCX6OQ3DkcsbYNE6H8uQQuVA',\n",
    "               'UCk8GzjMOrta8yxDcKfylJYw',\n",
    "               'UCvlE5gTbOvjiolFlEm-c_Ow',\n",
    "               'UCJplp5SjeGSdVdwsfb9Q7lQ',\n",
    "               'UCFFbwnve3yF62-tVXkTyHqg',\n",
    "               'UCJ5v_MCY6GNUBTO8-D3XoAg'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to establish connection to youtube data API using  API Key\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "\n",
    "# Get credentials and create an API client\n",
    "youtube = build(\n",
    "    api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_stats = pd.DataFrame() # Data frame to store channel statistics\n",
    "video_df = pd.DataFrame() # Data frame to store video details\n",
    "comments_df = pd.DataFrame() # Data frame to store comments info\n",
    "most_popular_videos = pd.DataFrame() # Data frame to store region wise most popular video info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to collect data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucntion to get channel statistics\n",
    "\n",
    "def get_channel_stats(youtube, channel_ids): \n",
    "    all_data = []\n",
    "\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=','.join(channel_ids))\n",
    "    response = request.execute()\n",
    "    \n",
    "    #loop through items\n",
    "    for item in response['items']:\n",
    "        data = {'channelName': item['snippet']['title'],\n",
    "               'subscribers': item['statistics']['subscriberCount'],\n",
    "               'views': item['statistics']['viewCount'],\n",
    "               'totalVideos': item['statistics']['videoCount'],\n",
    "               'playlistId': item['contentDetails']['relatedPlaylists']['uploads']\n",
    "                }\n",
    "        all_data.append(data)\n",
    "        \n",
    "    return(pd.DataFrame(all_data)) #Returns a data frame\n",
    "\n",
    "# Function to get video ids\n",
    "\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet,contentDetails\",\n",
    "        playlistId= playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        video_ids.append(item['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    while next_page_token is not None:\n",
    "        \n",
    "        request = youtube.playlistItems().list(\n",
    "                    part=\"snippet,contentDetails\",\n",
    "                    playlistId= playlist_id,\n",
    "                    maxResults = 50,\n",
    "                    pageToken = next_page_token)\n",
    "        \n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            video_ids.append(item['contentDetails']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids\n",
    "\n",
    "\n",
    "# Function to get video details from video ids. Video ids are passed to this function as arguments and a data frame is returned\n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "\n",
    "    all_video_info = []\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id= ','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tag', 'publishedAt'],\n",
    "                            'statistics':['viewCount', 'likeCount','favoriteCount', 'commentCount'],\n",
    "                            'contentDetails': ['duration', 'definition', 'caption']}\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "        \n",
    "    return pd.DataFrame(all_video_info)\n",
    "\n",
    "#Function to get comments under videos\n",
    "\n",
    "def get_comments_in_videos(youtube, video_ids):\n",
    "\n",
    "\n",
    "    all_comments = []\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        try:   \n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "        \n",
    "            comments_in_video = [comment['snippet']['topLevelComment']['snippet']['textOriginal'] for comment in response['items'][0:10]]\n",
    "            comments_in_video_info = {'video_id': video_id, 'comments': comments_in_video}\n",
    "\n",
    "            all_comments.append(comments_in_video_info)\n",
    "            \n",
    "        except: \n",
    "            # When error occurs - most likely because comments are disabled on a video\n",
    "            print('Could not get comments for video ' + video_id)\n",
    "        \n",
    "    return pd.DataFrame(all_comments)\n",
    "\n",
    "# Below functions are used to collect data of most popular videos based on a region\n",
    "\n",
    "def get_response(region_code):\n",
    "    request = youtube.videos().list(\n",
    "            part=\"snippet, contentDetails, statistics\",\n",
    "            chart=\"mostPopular\",\n",
    "            regionCode=region_code\n",
    "        )\n",
    "    response = request.execute()\n",
    "    return response\n",
    "\n",
    "def get_next_page_data(response, next_page_token, region_code):\n",
    "    if(next_page_token): # at the end of the reponse, next_page_token will be null\n",
    "        request = youtube.videos().list(\n",
    "                part=\"snippet, contentDetails, statistics\",\n",
    "                chart=\"mostPopular\",\n",
    "                regionCode=region_code,\n",
    "                maxResults = 50,\n",
    "                pageToken = next_page_token)\n",
    "        \n",
    "        response = request.execute()\n",
    "        return response\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def filter_api_response(response):\n",
    "\n",
    "    all_video_info = []\n",
    "\n",
    "\n",
    "    for video in response['items']:\n",
    "        stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tag', 'publishedAt'],\n",
    "                        'statistics':['viewCount', 'likeCount','favoriteCount', 'commentCount'],\n",
    "                        'contentDetails': ['duration', 'definition', 'caption']}\n",
    "        video_info = {}\n",
    "        video_info['video_id'] = video['id']\n",
    "        for k in stats_to_keep.keys():\n",
    "            for v in stats_to_keep[k]:\n",
    "                try:\n",
    "                    video_info[v] = video[k][v]\n",
    "                except:\n",
    "                    video_info[v] = None\n",
    "\n",
    "        all_video_info.append(video_info)\n",
    "    \n",
    "    return pd.DataFrame(all_video_info)\n",
    "#JSON(response)\n",
    "\n",
    "def get_n_rows_data(response, max_number_of_rows, region_code):\n",
    "    # response = get_data()\n",
    "    df_list = []\n",
    "    df_list.append(filter_api_response(response))\n",
    "\n",
    "    number_of_rows = 0\n",
    "\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    while(response.get('nextPageToken')):\n",
    "        df_list.append(filter_api_response(get_next_page_data(response, next_page_token, region_code)))\n",
    "        number_of_rows += 50\n",
    "        if(number_of_rows == max_number_of_rows):\n",
    "            break\n",
    "\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def get_region_wise_data(region_code_list):\n",
    "    video_data_df_list = []\n",
    "    for region_code in region_code_list:\n",
    "        response = get_response(region_code)\n",
    "        video_data_df_list.append(get_n_rows_data(response, 50, region_code)) # will contain duplicates\n",
    "    return pd.concat(video_data_df_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now performing Data collection to above Dataframes using the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading channel stats datafame\n",
    "\n",
    "channel_stats = get_channel_stats(youtube, channel_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#collecting video ids of all the videos. \n",
    "\n",
    "#Copying playlist id and channel name to a list from channel stats dataframe. \n",
    "\n",
    "playlist_id_copy = channel_stats['playlistId'].tolist()  # Copying playlist ids of each channel into a seperate list. \n",
    "print(len(playlist_id_copy))\n",
    "\n",
    "channel_name = channel_stats['channelName'].tolist() # copying all the channel name into a seperate4 list\n",
    "print(len(channel_name))\n",
    "\n",
    "# Creating a dict to store video ids of correspoding channels\n",
    "\n",
    "dict_channel_vids = {}\n",
    "\n",
    "for i in range(len(channel_name)):\n",
    "    dict_channel_vids[channel_name[i]] = 0 # initializing the values in dict with 0. \n",
    "\n",
    "# storing all video ids as a list as values to corresponding YT channels\n",
    "for i in range(len(playlist_id_copy)):                            \n",
    "    video_ids = get_video_ids(youtube, playlist_id_copy[i])\n",
    "    dict_channel_vids[channel_name[i]] = video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading video_df dataframe\n",
    "\n",
    "dict_copy = dict_channel_vids\n",
    "dict_copy.keys()\n",
    "\n",
    "for i in range(len(dict_channel_vids.keys())):                            \n",
    "    video_df= video_df.append(get_video_details(youtube, dict_channel_vids[channel_name[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading comments_df dataframe\n",
    "\n",
    "# Taking only the first 10 comments of first 100 videos in a channel\n",
    "\n",
    "for i in range(len(dict_channel_vids.keys())):                            \n",
    "    temp = dict_copy[channel_name[i]]\n",
    "    newList = temp[:100] \n",
    "    comments_df= comments_df.append(get_comments_in_videos(youtube, newList), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading most_popular_videos dataframe\n",
    "\n",
    "region_code_list = ['GB', 'BE', 'DK', 'DE', 'EE','IE'] # Country code of few european countries\n",
    "most_popular_videos = get_region_wise_data(region_code_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data exploration and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelName</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>views</th>\n",
       "      <th>totalVideos</th>\n",
       "      <th>playlistId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like Nastya</td>\n",
       "      <td>105000000</td>\n",
       "      <td>89475741563</td>\n",
       "      <td>786</td>\n",
       "      <td>UUJplp5SjeGSdVdwsfb9Q7lQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zee Music Company</td>\n",
       "      <td>94700000</td>\n",
       "      <td>56140625139</td>\n",
       "      <td>8151</td>\n",
       "      <td>UUFFbwnve3yF62-tVXkTyHqg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T-Series</td>\n",
       "      <td>241000000</td>\n",
       "      <td>222369697948</td>\n",
       "      <td>19586</td>\n",
       "      <td>UUq-Fj5jknLsUf-MWSy4_brA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SET India</td>\n",
       "      <td>155000000</td>\n",
       "      <td>144390080595</td>\n",
       "      <td>111056</td>\n",
       "      <td>UUpEhnqL0y41EpW2TvWAHD7Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vlad and Niki</td>\n",
       "      <td>96600000</td>\n",
       "      <td>75429474956</td>\n",
       "      <td>551</td>\n",
       "      <td>UUvlE5gTbOvjiolFlEm-c_Ow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>111000000</td>\n",
       "      <td>28984754763</td>\n",
       "      <td>4709</td>\n",
       "      <td>UU-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MrBeast</td>\n",
       "      <td>150000000</td>\n",
       "      <td>25527580754</td>\n",
       "      <td>741</td>\n",
       "      <td>UUX6OQ3DkcsbYNE6H8uQQuVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WWE</td>\n",
       "      <td>94700000</td>\n",
       "      <td>75897588295</td>\n",
       "      <td>68408</td>\n",
       "      <td>UUJ5v_MCY6GNUBTO8-D3XoAg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>‚úø Kids Diana Show</td>\n",
       "      <td>110000000</td>\n",
       "      <td>91133967627</td>\n",
       "      <td>1088</td>\n",
       "      <td>UUk8GzjMOrta8yxDcKfylJYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>158000000</td>\n",
       "      <td>159060348408</td>\n",
       "      <td>901</td>\n",
       "      <td>UUbCmjCuTUZos6Inko4u57UQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  channelName subscribers         views totalVideos  \\\n",
       "0                 Like Nastya   105000000   89475741563         786   \n",
       "1           Zee Music Company    94700000   56140625139        8151   \n",
       "2                    T-Series   241000000  222369697948       19586   \n",
       "3                   SET India   155000000  144390080595      111056   \n",
       "4               Vlad and Niki    96600000   75429474956         551   \n",
       "5                   PewDiePie   111000000   28984754763        4709   \n",
       "6                     MrBeast   150000000   25527580754         741   \n",
       "7                         WWE    94700000   75897588295       68408   \n",
       "8           ‚úø Kids Diana Show   110000000   91133967627        1088   \n",
       "9  Cocomelon - Nursery Rhymes   158000000  159060348408         901   \n",
       "\n",
       "                 playlistId  \n",
       "0  UUJplp5SjeGSdVdwsfb9Q7lQ  \n",
       "1  UUFFbwnve3yF62-tVXkTyHqg  \n",
       "2  UUq-Fj5jknLsUf-MWSy4_brA  \n",
       "3  UUpEhnqL0y41EpW2TvWAHD7Q  \n",
       "4  UUvlE5gTbOvjiolFlEm-c_Ow  \n",
       "5  UU-lHJZR3Gqxm24_Vd_AJ5Yw  \n",
       "6  UUX6OQ3DkcsbYNE6H8uQQuVA  \n",
       "7  UUJ5v_MCY6GNUBTO8-D3XoAg  \n",
       "8  UUk8GzjMOrta8yxDcKfylJYw  \n",
       "9  UUbCmjCuTUZos6Inko4u57UQ  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tag</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>duration</th>\n",
       "      <th>definition</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eaHkDAQ6wdo</td>\n",
       "      <td>Like Nastya</td>\n",
       "      <td>Nastya and Evelyn help each other as best friends</td>\n",
       "      <td>Friendship is not only fun, but also helping e...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-04T08:00:17Z</td>\n",
       "      <td>1230842</td>\n",
       "      <td>5357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PT5M27S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kPoi8UYlluU</td>\n",
       "      <td>Like Nastya</td>\n",
       "      <td>Nastya and Flower dance trend</td>\n",
       "      <td>Nastya and Flower dance trend #shorts</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-02T08:00:29Z</td>\n",
       "      <td>1241515</td>\n",
       "      <td>37294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PT17S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dk7mJHOSUfg</td>\n",
       "      <td>Like Nastya</td>\n",
       "      <td>Nastya and stories about diversity among kids</td>\n",
       "      <td>A collection of stories about the diversity of...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-30T09:00:08Z</td>\n",
       "      <td>1191566</td>\n",
       "      <td>4960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PT16M32S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ar4gmOGp6qA</td>\n",
       "      <td>Like Nastya</td>\n",
       "      <td>Nastya arranged a test of patience for the kids</td>\n",
       "      <td>Nastya arranged an endurance test for 5 kids. ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-27T09:00:05Z</td>\n",
       "      <td>2294545</td>\n",
       "      <td>7652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PT4M32S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PB1STAJV3LY</td>\n",
       "      <td>Like Nastya</td>\n",
       "      <td>Nastya and Evelyn - funny dance</td>\n",
       "      <td>Dance fun dances with us and upload to the #sh...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25T13:08:33Z</td>\n",
       "      <td>2275831</td>\n",
       "      <td>47851</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PT18S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>tVpgEiBcw7M</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>Learn the ABCs: \"P\" is for Pig and Penguin</td>\n",
       "      <td>Featuring the letter \"P\"! \\nThis series goes t...</td>\n",
       "      <td>None</td>\n",
       "      <td>2007-06-20T03:41:46Z</td>\n",
       "      <td>9272776</td>\n",
       "      <td>4678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PT1M31S</td>\n",
       "      <td>sd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>7W6fEFixi5U</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>Learn the ABCs: \"L\" is for Lion and Ladybug</td>\n",
       "      <td>Featuring the letter \"L\"! \\nThis series goes t...</td>\n",
       "      <td>None</td>\n",
       "      <td>2007-06-20T03:34:33Z</td>\n",
       "      <td>24207837</td>\n",
       "      <td>21365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PT1M48S</td>\n",
       "      <td>sd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>cgC8BC1OINQ</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>Learn the ABCs: \"K\" is for Kangaroo</td>\n",
       "      <td>Featuring the letter \"K\"! \\nThis series goes t...</td>\n",
       "      <td>None</td>\n",
       "      <td>2007-06-20T01:31:32Z</td>\n",
       "      <td>8514801</td>\n",
       "      <td>4386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PT2M13S</td>\n",
       "      <td>sd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>0fw3l1z9CUQ</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>ABC Song with Cute Ending</td>\n",
       "      <td>This ABC Song is one of the most popular ABC s...</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-09-02T01:34:53Z</td>\n",
       "      <td>289835096</td>\n",
       "      <td>328422</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PT45S</td>\n",
       "      <td>sd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>yfZ29cVaaVQ</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>ABC Song</td>\n",
       "      <td>A fast and funny song sung by a child and gran...</td>\n",
       "      <td>None</td>\n",
       "      <td>2006-09-01T23:39:09Z</td>\n",
       "      <td>27689423</td>\n",
       "      <td>37449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PT30S</td>\n",
       "      <td>sd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75794 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                channelTitle  \\\n",
       "0    eaHkDAQ6wdo                 Like Nastya   \n",
       "1    kPoi8UYlluU                 Like Nastya   \n",
       "2    Dk7mJHOSUfg                 Like Nastya   \n",
       "3    Ar4gmOGp6qA                 Like Nastya   \n",
       "4    PB1STAJV3LY                 Like Nastya   \n",
       "..           ...                         ...   \n",
       "897  tVpgEiBcw7M  Cocomelon - Nursery Rhymes   \n",
       "898  7W6fEFixi5U  Cocomelon - Nursery Rhymes   \n",
       "899  cgC8BC1OINQ  Cocomelon - Nursery Rhymes   \n",
       "900  0fw3l1z9CUQ  Cocomelon - Nursery Rhymes   \n",
       "901  yfZ29cVaaVQ  Cocomelon - Nursery Rhymes   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Nastya and Evelyn help each other as best friends   \n",
       "1                        Nastya and Flower dance trend   \n",
       "2        Nastya and stories about diversity among kids   \n",
       "3      Nastya arranged a test of patience for the kids   \n",
       "4                      Nastya and Evelyn - funny dance   \n",
       "..                                                 ...   \n",
       "897         Learn the ABCs: \"P\" is for Pig and Penguin   \n",
       "898        Learn the ABCs: \"L\" is for Lion and Ladybug   \n",
       "899                Learn the ABCs: \"K\" is for Kangaroo   \n",
       "900                          ABC Song with Cute Ending   \n",
       "901                                           ABC Song   \n",
       "\n",
       "                                           description   tag  \\\n",
       "0    Friendship is not only fun, but also helping e...  None   \n",
       "1                Nastya and Flower dance trend #shorts  None   \n",
       "2    A collection of stories about the diversity of...  None   \n",
       "3    Nastya arranged an endurance test for 5 kids. ...  None   \n",
       "4    Dance fun dances with us and upload to the #sh...  None   \n",
       "..                                                 ...   ...   \n",
       "897  Featuring the letter \"P\"! \\nThis series goes t...  None   \n",
       "898  Featuring the letter \"L\"! \\nThis series goes t...  None   \n",
       "899  Featuring the letter \"K\"! \\nThis series goes t...  None   \n",
       "900  This ABC Song is one of the most popular ABC s...  None   \n",
       "901  A fast and funny song sung by a child and gran...  None   \n",
       "\n",
       "              publishedAt  viewCount likeCount favoriteCount commentCount  \\\n",
       "0    2023-05-04T08:00:17Z    1230842      5357             0            0   \n",
       "1    2023-05-02T08:00:29Z    1241515     37294             0            0   \n",
       "2    2023-04-30T09:00:08Z    1191566      4960             0            0   \n",
       "3    2023-04-27T09:00:05Z    2294545      7652             0            0   \n",
       "4    2023-04-25T13:08:33Z    2275831     47851             0            0   \n",
       "..                    ...        ...       ...           ...          ...   \n",
       "897  2007-06-20T03:41:46Z    9272776      4678             0            0   \n",
       "898  2007-06-20T03:34:33Z   24207837     21365             0            0   \n",
       "899  2007-06-20T01:31:32Z    8514801      4386             0            0   \n",
       "900  2006-09-02T01:34:53Z  289835096    328422             0            0   \n",
       "901  2006-09-01T23:39:09Z   27689423     37449             0            0   \n",
       "\n",
       "     duration definition caption  \n",
       "0     PT5M27S         hd   false  \n",
       "1       PT17S         hd   false  \n",
       "2    PT16M32S         hd   false  \n",
       "3     PT4M32S         hd   false  \n",
       "4       PT18S         hd   false  \n",
       "..        ...        ...     ...  \n",
       "897   PT1M31S         sd   false  \n",
       "898   PT1M48S         sd   false  \n",
       "899   PT2M13S         sd   false  \n",
       "900     PT45S         sd   false  \n",
       "901     PT30S         sd   false  \n",
       "\n",
       "[75794 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gu-LlRSEDv0</td>\n",
       "      <td>[the edits are üî•, Super, Ye kuposhit bacha kya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rC-tcyFaUUs</td>\n",
       "      <td>[Touching lyrics accompanied by melody full wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qWd30w6f1qE</td>\n",
       "      <td>[üò¢üò¢, ‚ù§‚ù§‚ù§, ‚ù§‚ù§‚ù§‚ù§, üò¢üò¢üò¢üò¢, üòÆüòÆ, üî• üö©M\" Respect Everyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tRUtoAw_e8Y</td>\n",
       "      <td>[beautiful  welcome ü•∞ü•∞, https://youtu.be/8AFNV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eCXqMHPlaoE</td>\n",
       "      <td>[Superbüéâ‚ù§, Nice work from vinod paliwal and al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>rvUJr1QXor8</td>\n",
       "      <td>[üòÇüòÇüòÇüòÇüëéüëéüëéüëéüëéüëéüëéüëé, Who will stop SmackDown Womens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>L0pGH1D6P1Y</td>\n",
       "      <td>[We miss Pat McAfee &amp; Sarah Schreiber., üòÇ, I d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>G56Bhb-kPCA</td>\n",
       "      <td>[Brock lesnar I want to see compete for that b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>l1e8sShMF0I</td>\n",
       "      <td>[walah, i love that, We need Randy Orton baaaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>mO4cJ0a257A</td>\n",
       "      <td>[Finishing broken head, Win for 2, Wow, YEP,AN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id                                           comments\n",
       "0    gu-LlRSEDv0  [the edits are üî•, Super, Ye kuposhit bacha kya...\n",
       "1    rC-tcyFaUUs  [Touching lyrics accompanied by melody full wi...\n",
       "2    qWd30w6f1qE  [üò¢üò¢, ‚ù§‚ù§‚ù§, ‚ù§‚ù§‚ù§‚ù§, üò¢üò¢üò¢üò¢, üòÆüòÆ, üî• üö©M\" Respect Everyo...\n",
       "3    tRUtoAw_e8Y  [beautiful  welcome ü•∞ü•∞, https://youtu.be/8AFNV...\n",
       "4    eCXqMHPlaoE  [Superbüéâ‚ù§, Nice work from vinod paliwal and al...\n",
       "..           ...                                                ...\n",
       "592  rvUJr1QXor8  [üòÇüòÇüòÇüòÇüëéüëéüëéüëéüëéüëéüëéüëé, Who will stop SmackDown Womens ...\n",
       "593  L0pGH1D6P1Y  [We miss Pat McAfee & Sarah Schreiber., üòÇ, I d...\n",
       "594  G56Bhb-kPCA  [Brock lesnar I want to see compete for that b...\n",
       "595  l1e8sShMF0I  [walah, i love that, We need Randy Orton baaaa...\n",
       "596  mO4cJ0a257A  [Finishing broken head, Win for 2, Wow, YEP,AN...\n",
       "\n",
       "[597 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tag</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>duration</th>\n",
       "      <th>definition</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zcbsqsLEL_Y</td>\n",
       "      <td>The United Stand</td>\n",
       "      <td>BRIGHTON vs MANCHESTER UNITED LIVE STREAM Watc...</td>\n",
       "      <td>Unlock an EXCLUSIVE 40% Off ALL* boohooMAN Men...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-04T21:13:06Z</td>\n",
       "      <td>451821</td>\n",
       "      <td>7602</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>PT3H37S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ibVqF9NuGDU</td>\n",
       "      <td>Tion Wayne</td>\n",
       "      <td>Tion Wayne - Healing (Official Music Video)</td>\n",
       "      <td>Directed by Wowa (https://www.instagram.com/wo...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-04T20:22:17Z</td>\n",
       "      <td>496914</td>\n",
       "      <td>97196</td>\n",
       "      <td>0</td>\n",
       "      <td>11365</td>\n",
       "      <td>PT3M1S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vPvTkhIntjw</td>\n",
       "      <td>The United Stand</td>\n",
       "      <td>ATTACK TO BLAME! Brighton 1-0 Manchester Unite...</td>\n",
       "      <td>Brighton 1-0 Manchester United! Mark Goldbridg...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-04T21:40:27Z</td>\n",
       "      <td>233758</td>\n",
       "      <td>5741</td>\n",
       "      <td>0</td>\n",
       "      <td>826</td>\n",
       "      <td>PT29M54S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIAT31WlZqI</td>\n",
       "      <td>Behzinga</td>\n",
       "      <td>I‚Äôm Having A Surgery‚Ä¶</td>\n",
       "      <td>üí™ Gymshark: https://gym.sh/EthanGS\\nüíæ Second C...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-04T17:09:11Z</td>\n",
       "      <td>465318</td>\n",
       "      <td>48923</td>\n",
       "      <td>0</td>\n",
       "      <td>975</td>\n",
       "      <td>PT6M1S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F4mUnmFbVNg</td>\n",
       "      <td>Ren</td>\n",
       "      <td>Ren - Animal Flow</td>\n",
       "      <td>http://found.ee/Ren-Animal-Flow\\n\\nhttp://www....</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-04T19:00:08Z</td>\n",
       "      <td>251303</td>\n",
       "      <td>34996</td>\n",
       "      <td>0</td>\n",
       "      <td>4625</td>\n",
       "      <td>PT2M56S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>eDnrAGSjP3k</td>\n",
       "      <td>DAZN UEFA Women's Champions League</td>\n",
       "      <td>Arsenal vs. Wolfsburg | UEFA Women's Champions...</td>\n",
       "      <td>üá©üá™ üéôÔ∏è üëâ https://youtube.com/live/ET86gczHcrI?f...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-01T20:25:12Z</td>\n",
       "      <td>1095379</td>\n",
       "      <td>13759</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>PT3H51M20S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>j3ILbiok_1E</td>\n",
       "      <td>Nutshell Animations</td>\n",
       "      <td>1 2 BUCKLE MY SHOE (Animation Meme)</td>\n",
       "      <td>Subscribe to My Gaming Channel:\\nhttps://www.y...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-24T21:00:18Z</td>\n",
       "      <td>8721683</td>\n",
       "      <td>451832</td>\n",
       "      <td>0</td>\n",
       "      <td>5461</td>\n",
       "      <td>PT18S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Vo8dSsbIppg</td>\n",
       "      <td>Scene City</td>\n",
       "      <td>Miles Intentionally Fails Test | Spider-Man: I...</td>\n",
       "      <td>Miles (Shameik Moore) fails his test on purpos...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-19T03:00:12Z</td>\n",
       "      <td>4474821</td>\n",
       "      <td>390719</td>\n",
       "      <td>0</td>\n",
       "      <td>4412</td>\n",
       "      <td>PT28S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>vPvTkhIntjw</td>\n",
       "      <td>The United Stand</td>\n",
       "      <td>ATTACK TO BLAME! Brighton 1-0 Manchester Unite...</td>\n",
       "      <td>Brighton 1-0 Manchester United! Mark Goldbridg...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-04T21:40:27Z</td>\n",
       "      <td>233758</td>\n",
       "      <td>5741</td>\n",
       "      <td>0</td>\n",
       "      <td>826</td>\n",
       "      <td>PT29M54S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>7nWUrMM0cp8</td>\n",
       "      <td>Influenced by DEXERTO</td>\n",
       "      <td>Logan Paul and KSI Release NEW Prime Flavor!</td>\n",
       "      <td>Logan Paul and KSI‚Äôs Prime success continues‚Ä¶ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-01T22:15:36Z</td>\n",
       "      <td>1340811</td>\n",
       "      <td>74377</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>PT27S</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       video_id                        channelTitle  \\\n",
       "0   zcbsqsLEL_Y                    The United Stand   \n",
       "1   ibVqF9NuGDU                          Tion Wayne   \n",
       "2   vPvTkhIntjw                    The United Stand   \n",
       "3   DIAT31WlZqI                            Behzinga   \n",
       "4   F4mUnmFbVNg                                 Ren   \n",
       "..          ...                                 ...   \n",
       "45  eDnrAGSjP3k  DAZN UEFA Women's Champions League   \n",
       "46  j3ILbiok_1E                 Nutshell Animations   \n",
       "47  Vo8dSsbIppg                          Scene City   \n",
       "48  vPvTkhIntjw                    The United Stand   \n",
       "49  7nWUrMM0cp8               Influenced by DEXERTO   \n",
       "\n",
       "                                                title  \\\n",
       "0   BRIGHTON vs MANCHESTER UNITED LIVE STREAM Watc...   \n",
       "1         Tion Wayne - Healing (Official Music Video)   \n",
       "2   ATTACK TO BLAME! Brighton 1-0 Manchester Unite...   \n",
       "3                               I‚Äôm Having A Surgery‚Ä¶   \n",
       "4                                   Ren - Animal Flow   \n",
       "..                                                ...   \n",
       "45  Arsenal vs. Wolfsburg | UEFA Women's Champions...   \n",
       "46                1 2 BUCKLE MY SHOE (Animation Meme)   \n",
       "47  Miles Intentionally Fails Test | Spider-Man: I...   \n",
       "48  ATTACK TO BLAME! Brighton 1-0 Manchester Unite...   \n",
       "49       Logan Paul and KSI Release NEW Prime Flavor!   \n",
       "\n",
       "                                          description   tag  \\\n",
       "0   Unlock an EXCLUSIVE 40% Off ALL* boohooMAN Men...  None   \n",
       "1   Directed by Wowa (https://www.instagram.com/wo...  None   \n",
       "2   Brighton 1-0 Manchester United! Mark Goldbridg...  None   \n",
       "3   üí™ Gymshark: https://gym.sh/EthanGS\\nüíæ Second C...  None   \n",
       "4   http://found.ee/Ren-Animal-Flow\\n\\nhttp://www....  None   \n",
       "..                                                ...   ...   \n",
       "45  üá©üá™ üéôÔ∏è üëâ https://youtube.com/live/ET86gczHcrI?f...  None   \n",
       "46  Subscribe to My Gaming Channel:\\nhttps://www.y...  None   \n",
       "47  Miles (Shameik Moore) fails his test on purpos...  None   \n",
       "48  Brighton 1-0 Manchester United! Mark Goldbridg...  None   \n",
       "49  Logan Paul and KSI‚Äôs Prime success continues‚Ä¶ ...  None   \n",
       "\n",
       "             publishedAt viewCount likeCount favoriteCount commentCount  \\\n",
       "0   2023-05-04T21:13:06Z    451821      7602             0          451   \n",
       "1   2023-05-04T20:22:17Z    496914     97196             0        11365   \n",
       "2   2023-05-04T21:40:27Z    233758      5741             0          826   \n",
       "3   2023-05-04T17:09:11Z    465318     48923             0          975   \n",
       "4   2023-05-04T19:00:08Z    251303     34996             0         4625   \n",
       "..                   ...       ...       ...           ...          ...   \n",
       "45  2023-05-01T20:25:12Z   1095379     13759             0           98   \n",
       "46  2023-04-24T21:00:18Z   8721683    451832             0         5461   \n",
       "47  2023-04-19T03:00:12Z   4474821    390719             0         4412   \n",
       "48  2023-05-04T21:40:27Z    233758      5741             0          826   \n",
       "49  2023-05-01T22:15:36Z   1340811     74377             0          149   \n",
       "\n",
       "      duration definition caption  \n",
       "0      PT3H37S         hd   false  \n",
       "1       PT3M1S         hd   false  \n",
       "2     PT29M54S         hd   false  \n",
       "3       PT6M1S         hd   false  \n",
       "4      PT2M56S         hd   false  \n",
       "..         ...        ...     ...  \n",
       "45  PT3H51M20S         hd   false  \n",
       "46       PT18S         hd   false  \n",
       "47       PT28S         hd   false  \n",
       "48    PT29M54S         hd   false  \n",
       "49       PT27S         hd   false  \n",
       "\n",
       "[330 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_popular_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   channelName  10 non-null     object\n",
      " 1   subscribers  10 non-null     object\n",
      " 2   views        10 non-null     object\n",
      " 3   totalVideos  10 non-null     object\n",
      " 4   playlistId   10 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 528.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "channel_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 75794 entries, 0 to 901\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   video_id       75794 non-null  object\n",
      " 1   channelTitle   75794 non-null  object\n",
      " 2   title          75794 non-null  object\n",
      " 3   description    75794 non-null  object\n",
      " 4   tag            0 non-null      object\n",
      " 5   publishedAt    75794 non-null  object\n",
      " 6   viewCount      75784 non-null  object\n",
      " 7   likeCount      75299 non-null  object\n",
      " 8   favoriteCount  75794 non-null  object\n",
      " 9   commentCount   73353 non-null  object\n",
      " 10  duration       75794 non-null  object\n",
      " 11  definition     75794 non-null  object\n",
      " 12  caption        75794 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "video_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 597 entries, 0 to 596\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   video_id  597 non-null    object\n",
      " 1   comments  597 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.5+ KB\n"
     ]
    }
   ],
   "source": [
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 330 entries, 0 to 49\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   video_id       330 non-null    object\n",
      " 1   channelTitle   330 non-null    object\n",
      " 2   title          330 non-null    object\n",
      " 3   description    330 non-null    object\n",
      " 4   tag            0 non-null      object\n",
      " 5   publishedAt    330 non-null    object\n",
      " 6   viewCount      330 non-null    object\n",
      " 7   likeCount      327 non-null    object\n",
      " 8   favoriteCount  330 non-null    object\n",
      " 9   commentCount   325 non-null    object\n",
      " 10  duration       330 non-null    object\n",
      " 11  definition     330 non-null    object\n",
      " 12  caption        330 non-null    object\n",
      "dtypes: object(13)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "most_popular_videos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75794, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_popular_videos.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
